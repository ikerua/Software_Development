{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56d080fc",
   "metadata": {},
   "source": [
    "# Data Preparation and Model Training\n",
    "\n",
    "This notebook demonstrates the workflow for preparing the house price dataset, training a regression model, making predictions, and analyzing results.\n",
    "\n",
    "## 1. Import Required Libraries and Modules\n",
    "\n",
    "We start by importing necessary libraries and modules, and setting up the Python path to allow imports from the project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f2ceb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Add the parent directory to sys.path to allow imports from my_project\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from my_project.dataset import HousePricingDataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa3887e",
   "metadata": {},
   "source": [
    "## 2. Initialize and Prepare Data\n",
    "\n",
    "We initialize the data module and process the raw dataset to prepare it for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82a42d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded with shape: (1000, 8)\n",
      "Features shape: (1000, 7), Target shape: (1000,)\n",
      "Data split into train, val, and test sets. Interim files saved.\n",
      "Data normalized and processed files saved.\n"
     ]
    }
   ],
   "source": [
    "# Initialize data module and process data\n",
    "dataModule = HousePricingDataModule(data_dir='../data/raw/house_price_regression_dataset.csv')\n",
    "dataModule.prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f428bad",
   "metadata": {},
   "source": [
    "## 3. Train the Model\n",
    "\n",
    "We train the house price regression model using the processed data. Training parameters such as batch size, learning rate, and number of epochs are specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0cd12f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type       | Params | Mode \n",
      "-----------------------------------------------\n",
      "0 | net     | Sequential | 2.6 K  | train\n",
      "1 | loss_fn | MSELoss    | 0      | train\n",
      "-----------------------------------------------\n",
      "2.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.6 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "\n",
      "  | Name    | Type       | Params | Mode \n",
      "-----------------------------------------------\n",
      "0 | net     | Sequential | 2.6 K  | train\n",
      "1 | loss_fn | MSELoss    | 0      | train\n",
      "-----------------------------------------------\n",
      "2.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.6 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joaqu\\Desktop\\MASTER\\Software Development\\Practice 1\\Software_Development\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:428: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joaqu\\Desktop\\MASTER\\Software Development\\Practice 1\\Software_Development\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:428: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 10/10 [00:05<00:00,  1.76it/s, v_num=0, val_loss=4.86e+11, train_loss=4.34e+11]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 10/10 [00:05<00:00,  1.75it/s, v_num=0, val_loss=4.86e+11, train_loss=4.34e+11]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from my_project.modeling import train, predict\n",
    "import importlib\n",
    "import argparse\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# Simulate command-line arguments for train.main()\n",
    "args = argparse.Namespace(\n",
    "    batch_size=64,\n",
    "    num_workers=4,\n",
    "    lr=1e-3,\n",
    "    weight_decay=0.0,\n",
    "    epochs=20,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "train.main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2092b8b",
   "metadata": {},
   "source": [
    "## 4. Make Predictions\n",
    "\n",
    "After training, we use the trained model to make predictions on the test dataset. The predictions are saved to a CSV file for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7850e7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using checkpoint: c:\\Users\\joaqu\\Desktop\\MASTER\\Software Development\\Practice 1\\Software_Development\\models\\house_price_regressor.ckpt\n",
      "Test RMSE: 669855.877397\n",
      "Predictions saved to: c:\\Users\\joaqu\\Desktop\\MASTER\\Software Development\\Practice 1\\Software_Development\\models\\test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Run prediction\n",
    "output_csv = predict.run_predict(\n",
    "    data_dir=\"data/processed\",\n",
    "    models_dir=\"models\",\n",
    "    output_path=\"models/test_predictions.csv\",\n",
    "    device=\"auto\",\n",
    "    target_col=\"House_Price\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1e866d",
   "metadata": {},
   "source": [
    "## 5. Analyze Results\n",
    "\n",
    "Finally, we load the predictions and display the first few rows to inspect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65917f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119.993030</td>\n",
       "      <td>9.010005e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68.461914</td>\n",
       "      <td>4.945375e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129.482960</td>\n",
       "      <td>9.494042e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>213.007700</td>\n",
       "      <td>1.040389e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160.330430</td>\n",
       "      <td>7.940100e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction        y_true\n",
       "0  119.993030  9.010005e+05\n",
       "1   68.461914  4.945375e+05\n",
       "2  129.482960  9.494042e+05\n",
       "3  213.007700  1.040389e+06\n",
       "4  160.330430  7.940100e+05"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_preds = pd.read_csv(\"../models/test_predictions.csv\")\n",
    "df_preds.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
